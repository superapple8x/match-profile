# Development Setup Guide (Linux)

This guide provides a comprehensive, step-by-step walkthrough for setting up and running the Profile Matching application on a Linux system for development and testing, including the LLM-driven data analysis feature. It's designed to be easy to follow, even for beginners.

## Prerequisites

1.  **Operating System:** This guide assumes you are using a Debian/Ubuntu-based Linux distribution. Adapt the package installation commands accordingly if you are using a different distribution (e.g., Fedora, Arch).
2.  **Terminal Access:** You'll need a terminal to execute commands.
3.  **Basic Linux Knowledge:** Familiarity with basic Linux commands like `cd`, `ls`, `mkdir`, and `sudo` is helpful.

## Installing Prerequisites

1.  **Node.js and npm:** Node.js is a JavaScript runtime, and npm is its package manager. Install them using the following commands:

    ```bash
    sudo apt update
    sudo apt install nodejs npm
    ```

    Verify the installation by checking the versions:

    ```bash
    node -v
    npm -v
    ```

    A recent LTS version of Node.js (e.g., v18 or later) is recommended. If the installed version is older, you may need to use `nvm` (Node Version Manager) to install a newer version.

2.  **Git:** Git is a version control system used to clone the project repository. Install it using:

    ```bash
    sudo apt install git
    ```

    Verify the installation:

    ```bash
    git --version
    ```

3.  **Docker:** Docker is required for the sandboxed execution of Python code generated by the LLM analysis feature.

    ```bash
    sudo apt install docker.io
    sudo apt install docker-compose
    ```

    After installation, add your user to the `docker` group to avoid needing `sudo` for Docker commands:

    ```bash
    sudo usermod -aG docker ${USER}
    ```

    **Important:** Log out and log back in for this change to take effect. Verify by running `docker ps` without `sudo`:

    ```bash
    docker ps
    ```

    If you see a list of running containers (or an empty list), Docker is set up correctly. If you get a permission error, double-check that you've logged out and back in.

## Setting up PostgreSQL

1.  **Install PostgreSQL:** If you don't have PostgreSQL installed, install it using:

    ```bash
    sudo apt install postgresql postgresql-contrib
    ```

2.  **Create a Database User (if needed):** The default user is `postgres`. You may need to create a password for this user:

    ```bash
    sudo passwd postgres
    ```

    Then, switch to the `postgres` user:

    ```bash
    sudo -i -u postgres
    ```

    And set the password:

    ```bash
    psql -c "ALTER USER postgres PASSWORD 'your_password';"
    ```

    Replace `your_password` with a strong password. Exit the `postgres` user session:

    ```bash
    exit
    ```

3.  **Create a Database:** Create the `profile_matching` database:

    ```bash
    sudo -i -u postgres
    createdb profile_matching
    exit
    ```

4.  **Initialize/Migrate the Database Schema:** The database schema is no longer initialized automatically or via a raw SQL file. Database schema changes are managed using `node-pg-migrate`.

    *   Navigate to the backend directory:
        ```bash
        cd src/backend
        ```
    *   Run the migrations to set up or update the schema:
        ```bash
        npm run db:migrate:up
        ```
    *   This command reads the configuration from `db-migrate-config.js` (which uses the `.env` file for connection details) and applies any pending migrations found in the `migrations/` directory. You should run this command after cloning the repository for the first time and whenever new database migrations are added.

## Configuring the Backend

The backend requires environment variables for LLM configuration and database connection.

1.  **Create `.env` file:** In the `src/backend` directory, create a file named `.env`:

    ```bash
    cd src/backend
    touch .env
    ```

2.  **Edit `.env` file:** Open the `.env` file with a text editor (e.g., `nano`, `vim`, `gedit`) and add the following content. Replace the placeholder values with your actual API keys and database settings:

    ```bash
    nano .env
    ```

    Then, paste the following content into the file:

    ```dotenv
    # LLM Configuration
    LLM_PROVIDER=deepseek # Options: openai, deepseek (gemini, ollama not fully implemented)

    # --- API Keys & Config (Add your keys/prefs here) ---

    # OpenAI (if LLM_PROVIDER=openai)
    OPENAI_API_KEY=your_openai_key
    OPENAI_CODE_MODEL=gpt-3.5-turbo
    OPENAI_TEXT_MODEL=gpt-3.5-turbo

    # DeepSeek (if LLM_PROVIDER=deepseek)
    DEEPSEEK_API_KEY=your_deepseek_key
    DEEPSEEK_BASE_URL=https://api.deepseek.com/v1 # OpenAI compatible endpoint
    DEEPSEEK_CODE_MODEL=deepseek-coder # Or deepseek-chat, deepseek-reasoner
    DEEPSEEK_TEXT_MODEL=deepseek-chat # Or deepseek-reasoner

    # PostgreSQL Configuration
    DB_USER=postgres # Default: postgres
    DB_HOST=localhost # Default: localhost
    DB_NAME=profile_matching # Default: profile_matching
    DB_PASSWORD=your_db_password # Default: (empty string) - Set your actual password here
    DB_PORT=5432 # Default: 5432

    # JWT Configuration (Required for Authentication)
    # Generate a strong, random secret (e.g., using openssl rand -hex 32)
    JWT_SECRET=your_strong_random_jwt_secret_here
    JWT_EXPIRES_IN=1h # Optional: Default is 1 hour
    ```

    *   **LLM Configuration:**
        *   Set `LLM_PROVIDER` to the LLM service you want to use (e.g., `deepseek`).
        *   Fill in the corresponding API key (`DEEPSEEK_API_KEY` or `OPENAI_API_KEY`).
        *   You can optionally change the model names (e.g., `DEEPSEEK_CODE_MODEL`).
    *   **PostgreSQL Configuration:**
        *   These variables control how the backend connects to your PostgreSQL database. The defaults should work if you have a local PostgreSQL instance running with the default settings.
     *   **JWT Configuration:**
         *   `JWT_SECRET` is crucial for security. Generate a strong random string and paste it here. While the backend provides a default for non-production environments if this is missing, setting it explicitly is highly recommended.

## Running the Application

You need to run both the backend and frontend servers concurrently. Open two separate terminal windows or tabs in the project's root directory (`match-profile`).

1.  **Start the Backend Server:**

    *   In the first terminal, navigate to the backend directory:

        ```bash
        cd src/backend
        npm install # Install dependencies (run this after cloning or pulling changes)
        ```

    *   Then, start the server:

        ```bash
        npm start
        ```

    *   This command uses `node index.js` directly, suitable for basic development. Keep this terminal running.
    *   Alternatively, you can use `pm2` for more robust process management locally (useful for testing restarts, etc.): `npm run start:prod`. Use `pm2 logs` to view logs and `npm run stop:prod` to stop it.
    *   Logs will be generated in the `src/backend/logs/` directory (`combined.log`, `error.log`).
    *   The first time the LLM analysis feature is used, it may take a minute to build the necessary Docker image (`python-analysis-sandbox`).

2.  **Start the Frontend Development Server:**

    *   In the second terminal, navigate to the frontend directory:

        ```bash
        cd src/frontend
        ```

    *   Install dependencies if you haven't already: `npm install`
    *   Then, start the Vite development server:

        ```bash
        npm run dev
        ```

    *   Vite will compile the application and start a development server, usually on `http://localhost:5173`. It will also watch for file changes and automatically update the browser (Hot Module Replacement - HMR). Keep this terminal running.

## Accessing the Application

Once both servers are running:

1.  Open your web browser (e.g., Firefox, Chrome).
2.  Navigate to the frontend server's address, typically `http://localhost:5173`.

You should now be able to use the Profile Matching application.

*   Upload a CSV file using the "Choose File" and "Upload" buttons.
*   Perform a search using the Search Builder.
*   If results are found, click the "Analyze Results with LLM" button that appears below the results table.
*   Enter a natural language query in the analysis section (e.g., "Plot the distribution of Age") and click "Run Analysis".

The frontend will make requests to the backend server (proxied via Vite) for file import, matching, and LLM analysis.

## Stopping the Servers

To stop the servers, go to each terminal window where they are running and press `Ctrl + C`.

**Important Note:** The backend code contains a commented-out variable `BASE_UPLOAD_DIR` in `src/backend/routes/fileOperations.js`. This variable is **not used** and should **not** be uncommented or used for file storage. The application is designed to process uploaded files in memory, not to store them permanently on the server's file system.